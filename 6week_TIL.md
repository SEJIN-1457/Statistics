# 통계학 6주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_6th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

6주차는 `3부. 데이터 분석하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_6th_TIL

### 3부. 데이터 분석하기
### 12.통계 기반 분석 방법론



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | ✅      | 
|5주차| 2부 p.203~254  | ✅      | 
|6주차| 3부 p.300~356  | ✅      | 
|7주차| 3부 p.357~615  | 🍽️      |

<!-- 여기까진 그대로 둬 주세요-->

# 12.통계 기반 분석 방법론

```
✅ 학습 목표 :
* 주성분 분석(PCA)의 개념을 설명할 수 있다.
* 다중공선성을 진단할 수 있다.
* Z-TEST와 T-TEST의 개념을 비교하고, 적절한 상황에서 검정을 설계하고 수행할 수 있다.
* ANOVA TEST를 활용하여 세 개 이상의 그룹 간 평균 차이를 검정하고, 사후검정을 수행할 수 있다.
* 카이제곱 검정을 통해 범주형 변수 간의 독립성과 연관성을 분석하는 방법을 설명할 수 있다.
```

## 12.1. 분석 모델 개요
- 회귀분석 (연속형 종속변수 예측)
  - 종류 및 특징
    - 선형 회귀분석: 독립변수(X)로 종속변수(Y)를 예측. 최소제곱법으로 직선을 찾음
    - 다항 회귀분석: X-Y 관계가 곡선일 때 사용
    - Elastic Net, Ridge, Lasso
      - Ridge: L2 정규화 → 계수 크기 조절
      - Lasso: L1 정규화 → 중요도 낮은 변수 제거
      - Elastic Net: L1 + L2 결합
  - 필요 가정: 선형성, 정규성, 등분산성, 독립성
  - 다중공선성: VIF로 판단 (10 이상 → 문제 있음)
- 분류모델 (범주형 종속변수 예측)
  - 종류
    - 로지스틱 회귀: 이항 or 다항 분류, 결과를 확률로 변환, 0.5 기준 분류
      - 변수 유의성: Wald 통계량, p-value
      - 명목형 변수는 더미화, 수치형 변수는 스케일링
      - 클래스 불균형 시 언더샘플링/오버샘플링 활용
    - 의사결정나무 (Decision Tree): 분기 규칙 기반, 과적합 방지를 위한 가지치기 필요
    - 랜덤 포레스트: 여러 트리의 앙상블 → 과적합 방지, 예측 성능 향상
    - 선형 판별 분석 (LDA): 차원 축소 + 분류 최적화 (분산 비율 최대화)
    - SVM: 결정 경계 기반, 커널 기법 활용 (rbf 등), C와 Gamma 튜닝 필요
    - KNN: 거리 기반 분류, K 값이 성능에 영향, 스케일링 필수
- 시계열 분석 (시간 순서 데이터 예측)
  - 회귀 기반 예측: 과거 값을 독립변수로 사용
  - ARIMA: 자기회귀(AR), 이동평균(MA), 차분(I) 기반 모델
  - Auto-ARIMA: 최적 파라미터 자동 탐색
- 연관 분석 (항목 간 연관 규칙 도출)
  - 지표: 지지도(Support), 신뢰도(Confidence), 향상도(Lift)
  - 알고리즘: Apriori
- 클러스터링 (데이터의 유사성 기반 군집화)
  - K-평균: 군집 수 K 지정, 중심점과 거리 최소화
    - 초기 중심점 영향 큼 → k-means++로 개선
    - 최적 K 판단: 엘보우 기법, 실루엣 계수
    - 군집 간 통계 검정: t-test, ANOVA
  - DBSCAN: 밀도 기반, 군집 수 미리 지정 필요 없음
    - 이상치 처리 가능
    - 파라미터: ε, minPts
- 인공신경망
  - 기본 구조: 입력층 - 은닉층 - 출력층 / 오차역전파로 학습
  - CNN: 이미지 처리에 강점 (Convolution + Pooling)
  - RNN / LSTM: 시계열 등 순차 데이터 처리
    - LSTM은 장기 의존성 문제 보완
   

## 12.2. 주성분 분석(PCA)
- 목적: 고차원 데이터를 저차원으로 축소하여 핵심 정보만 보존
- 원리: 분산이 가장 큰 방향으로 새로운 축(주성분)을 생성
- LDA와의 유사점: 둘 다 차원 축소 기법
  - 차이점
    - PCA: 클래스 정보 없이 전체 분산 최대화  
    - LDA: 클래스 정보를 고려해 집단 간 분산/집단 내 분산 비율 최대화
      - LDA 실습 코드에서 n_components=1 옵션을 사용하여 차원을 축소하는 것을 보여줌.
    

## 12.4. 다중공선성 해결과 섀플리 밸류 분석
- 다중공선성: 독립변수 간 상관관계가 높아 회귀계수의 해석에 혼란 발생
- 검사 방법:
  - VIF (Variance Inflation Factor) 값 사용
  - 일반 기준: VIF > 10 → 다중공선성 존재 의심
- 해결 방법: 상관 높은 변수 제거, 변수 선택 기법 적용
- 회귀 해석의 신뢰성을 위해 사전 변수 점검 필수


## 12.6. Z-test와 T-test
- T-test: 회귀분석에서 독립변수의 통계적 유의성을 판단할 때 사용
- T Value: 회귀계수가 0이 아닐 확률적 강도 표현
- P Value: 귀무가설(회귀계수=0) 기각 여부 판단 지표
  - 일반 기준: P < 0.05 → 유의함
  - 대략 T Value의 절댓값이 1.98 이상이면 P < 0.05
- Z-test: 표본 크기가 충분히 크거나 모분산을 아는 경우 사용

## 12.7. ANOVA
- 목적: 셋 이상의 집단 간 평균 차이가 통계적으로 유의한지 검정
- LDA와의 연관성:
  - LDA는 ANOVA처럼 집단 간 분산 / 집단 내 분산 비율을 최대로 하는 판별 함수 생성
- 활용
  - K-평균 클러스터링 후, 군집 간 특성 차이의 유의성 검정
  - 각 군집의 평균 차이에 대한 ANOVA 또는 t-test 수행 가능

## 12.8. 카이제곱 검정(교차분석)
- 목적: 두 범주형 변수 간 독립성 또는 관련성 검정
- 로지스틱 회귀와의 연관성:
  - 회귀 결과에서 Wald Chi-Square 값 사용 → 변수의 유의성 평가
  - Pr(>|Chi|) 값이 작을수록 변수는 유의미 



<br>
<br>

# 확인 문제

### **문제 1.**
> **🧚 경희는 다트비 교육 연구소의 연구원이다. 경희는 이번에 새롭게 개발한 교육 프로그램이 기존 프로그램보다 학습 성취도 향상에 효과적인지 검증하고자 100명의 학생을 무작위로 두 그룹으로 나누어 한 그룹(A)은 새로운 교육 프로그램을, 다른 그룹(B)은 기존 교육 프로그램을 수강하도록 하였다. 실험을 시작하기 전, 두 그룹(A, B)의 초기 시험 점수 평균을 비교한 결과, 유의미한 차이가 없었다. 8주 후, 학생들의 최종 시험 점수를 수집하여 두 그룹 간 평균 점수를 비교하려고 한다.**   

> **🔍 Q1. 이 실험에서 사용할 적절한 검정 방법은 무엇인가요?**

```
두 집단의 평균을 비교하는 데 사용되는 통계적 검정 방법은 독립표본 t-검정이다. 
```

> **🔍 Q2. 이 실험에서 설정해야 할 귀무가설과 대립가설을 각각 작성하세요.**

```
귀무가설 (H₀): 새로운 교육 프로그램 그룹(A)과 기존 교육 프로그램 그룹(B) 간의 최종 시험 점수 평균에 유의미한 차이가 없다
대립가설 (H₁): 새로운 교육 프로그램 그룹(A)과 기존 교육 프로그램 그룹(B) 간의 최종 시험 점수 평균에 유의미한 차이가 있다
```

> **🔍 Q3. 검정을 수행하기 위한 절차를 순서대로 서술하세요.**

<!--P.337의 실습 코드 흐름을 확인하여 데이터를 불러온 후부터 어떤 절차로 검정을 수행해야 하는지 고민해보세요.-->

```
- 데이터 로드 : 실험에 참여한 100명 학생의 최종 시험 점수 데이터와 각 학생이 어떤 그룹(A 또는 B)에 속하는지에 대한 정보를 불러오
- 그룹별 데이터 분리 : 전체 학생 데이터에서 그룹 A와 그룹 B에 해당하는 최종 시험 점수 데이터를 각각 분리하
- 통계적 가정 확인 : 독립표본 t-검정을 수행하기 위한 가정이 충족되는지 확인하기(각 그룹 내 점수 분포의 정규성, 두 그룹의 분산 동질성 확인)
- t-검정 수행 : 분리된 그룹 A와 그룹 B의 최종 시험 점수 데이터를 사용하여 독립표본 t-검정을 수행
- 결과해석 : 산출된 p-값과 유의수준 비교

> **🔍 Q4. 이 검정을 수행할 때 가정해야 하는 통계적 조건을 설명하세요.**

```
- 독립성: 두 그룹의 표본이 서로 독립적이어야 한다
- 정규성: 각 그룹 내 최종 시험 점수 분포가 근사적으로 정규분포를 따라야 한다
- 등분산성: 두 그룹의 최종 시험 점수 분산이 서로 같아야 한다
```

> **🔍 Q5. 추가적으로 최신 AI 기반 교육 프로그램(C)도 도입하여 기존 프로그램(B) 및 새로운 프로그램(A)과 비교하여 성취도 차이가 있는지 평가하고자 한다면 어떤 검정 방법을 사용해야 하나요? 단, 실험을 시작하기 전, C 그룹의 초기 점수 평균도 A, B 그룹과 유의미한 차이가 없었다고 가정한다.**

```
세 개(A, B, C)의 독립적인 집단 간 최종 시험 점수 평균 차이를 비교하는 경우, 일원배치 분산분석을 사용하면 좋을 것 같다. 분산분석은 셋 이상의 집단 평균을 비교하는 데 적합한 방법이기 때문.
```

> **🔍 Q6. 5번에서 답한 검정을 수행한 결과, 유의미한 차이가 나타났다면 추가적으로 어떤 검정을 수행해 볼 수 있을까요?**

```
일원배치 분산분석 결과 통계적으로 유의미한 차이가 나타났다는 것은 세 그룹(A, B, C)의 평균이 '모두 같다'는 귀무가설을 기각한 것이다. 그러나 이는 세 그룹 중 적어도 한 쌍 이상에서 평균 차이가 존재함을 의미할 뿐, 구체적을 어떤 그룹쌍 간에 차이가 있는지 알 수 없기에 이에 대한 추가적인 사후검정이 필요하다.
```

---

### **문제 2. 카이제곱 검정**  
> **🧚 다음 중 어떠한 경우에 카이제곱 검정을 사용해야 하나요?   
1️⃣ 제품 A, B, C의 평균 매출 차이를 비교하고자 한다.  
2️⃣ 남성과 여성의 신체 건강 점수 평균 차이를 분석한다.  
3️⃣ 제품 구매 여부(구매/미구매)와 고객의 연령대(10대, 20대, 30대…) 간의 연관성을 분석한다.  
4️⃣ 특정 치료법이 환자의 혈압을 감소시키는 효과가 있는지 확인한다.**  

```
3️⃣ 제품 구매 여부(구매/미구매)와 고객의 연령대(10대, 20대, 30대…) 간의 연관성을 분석한다.  
```

### 🎉 수고하셨습니다.
